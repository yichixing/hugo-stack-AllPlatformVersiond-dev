+++
author = "taojl"
title = "Qwen3模型测试结果（包含能本地部署的小参数模型）"
collections = [
"多方位测试（知道从哪些方面测试模型，测试题自己想也想得到）",
"Qwen3不用开推理 其效果直逼推理模型，如果Qwen3开推理模型，那效果应该更恐怖",
"Qwen3的小参数模型开了推理后，其效果媲美甚至超过没开推理的Qwen3全参模型，因此即便能本地部署的小参数Qwen3也无需担心效果差",

]
date = "2025-01-28"
#description = "Sample article showcasing basic Markdown syntax and formatting for HTML elements."

categories = [
    "模型测试",
    "开源模型",
"有视觉推理能力的多模态模型能做什么"
]
tags = [
    "Qwen3全参模型不开推理也非常强大",
    "Qwen3小参数模型开了推理后 其效果常常能媲美甚至超过不开启思考模式的32B模型",
    "",
    "",
]

series = ["AI","AI模型测试","AI开源模型","AI适合本地部署小模型效果怎样"]
#aliases = ["migrate-from-jekyl"]
#image = "pawel-czerwinski-8uZPynIu-rQ-unsplash.jpg"

+++
༼🚀企业级最强开源大模型Qwen3震撼发布！本地部署+全面客观测评！Qwen3-235B-A22B+Qwen3-32B+Qwen3-14B谁是最强王者？ollama+LM Studio+vLLM本地部署 ༽
# part1: InternVL3 OCR能力测试 - 手写体识别

好的，这是视频中对Qwen3系列模型测试结果的总结：

# Part 1: Qwen3 模型基础能力与幻觉测试

(04:02-04:30) ***1.1: 知识库截止日期测试***
*   **测试类型**：知识库时效性。
*   **结果**：
    *   **Qwen3-235B-A22B** 的知识库截止日期为 **2024年6月**。
    *   **Qwen3-32B** 的知识库截止日期到 **2024年10月**。
    *   **Qwen3-14B** 的知识库截止日期到 **2024年10月**。
*   **作者观点**: 三款模型的知识都比较新。

(04:30-06:33) ***1.2: 幻觉测试（虚构信息辨别）***
*   **测试类型**：模型对明确虚构或不存在信息的辨别能力。
    *   数字大小比较 (2.999 vs 2.12345)
    *   英文单词字母统计 (stresslessness)
    *   虚构人物（量子信息学家马克·威尔逊教授）
    *   虚构化学物质（九氧化二氮）
    *   虚构历史事件（公元前235年秦国与齐国的“稷下之盟”）
    *   虚构物理理论（反熵矩阵理论）
    *   虚构文学事件（狄更斯和海明威在巴黎辩论）
*   **结果**：
    *   **数字比较**：三款模型（235B, 32B, 14B）均**正确**比较。
    *   **字母统计**：三款模型（235B, 32B, 14B）均**正确**统计。
    *   **虚构人物/化学物质/物理理论/文学事件**：三款模型（235B, 32B, 14B）基本都能**正确识别**出这些是虚构的，没有直接产生幻觉进行编造。**235B**和**32B**表现很好，**14B**（开启思考模式后）也能识别。
    *   **虚构历史事件**：
        *   **Qwen3-235B-A22B**：**正确**指出该事件没有明确记载。
        *   **Qwen3-32B**：**产生了幻觉**，编造了“稷下之盟”的细节内容，这是错误的。
        *   **Qwen3-14B**（开启思考模式）：**正确**指出该事件不存在。
*   **作者观点**: Qwen3在辨别虚构信息方面表现不错，尤其是235B和开启思考模式的14B。但32B在虚构历史事件上出现了明显幻觉。

# Part 2: Qwen3 模型逻辑推理与遵循指令能力测试

(07:02-08:15) ***2.1: 多维模式识别与逻辑推理测试***
*   **测试类型**：根据规则填充矩阵、寻找序列规律（字母、数字、二进制）。
    *   矩阵填充
    *   字母序列 (OTTFFSSEN...)
    *   交替数字序列 (3, 5, 6, 10, 9...)
    *   二进制序列 (1, 2, 4, 8...)
*   **结果**：
    *   **矩阵填充**：
        *   **Qwen3-235B-A22B**：**错误**，未能解决。
        *   **Qwen3-32B**：**错误**，未能解决。
        *   **Qwen3-14B**（开启思考模式）：**正确**解决。
    *   **序列规律**：三款模型（235B, 32B, 14B）对于字母、交替数字、二进制序列均能**正确**找出规律并补全。
*   **作者观点**: 在矩阵逻辑题上，14B开启思考模式后表现优于两个更大的模型。但在序列规律题上，三者表现都很好。

(08:15-08:30) ***2.2: JSON结构化输出能力测试***
*   **测试类型**：根据给定信息生成包含订单处理逻辑的JSON结构。
*   **输入指令**：请根据以下信息，生成一个包含订单处理逻辑的JSON结构：[包含客户信息、购物车商品、优惠券、物流选项、支付方式等信息]...请计算最终订单金额...
*   **结果**：
    *   **Qwen3-235B-A22B**：生成的**JSON格式正确**，但**折扣计算顺序出错**，导致最终金额有**误差**。
    *   **Qwen3-32B**：生成的**JSON格式正确**，但出现的**错误较多**。
    *   **Qwen3-14B**（开启思考模式）：生成的**JSON格式和计算结果均正确**。
*   **作者观点**: 14B开启思考模式后表现最好，235B次之，32B错误较多。

(09:01-09:35) ***2.3: 混合格式信息提取与结构化输出测试***
*   **测试类型**：将包含CSV、XML、普通文本的混合信息转换为统一的JSON格式。
*   **输入指令**：请将以下混合信息转换为统一的JSON格式：[包含CSV格式的产品信息、XML格式的供应商信息、普通文本的促销活动信息]
*   **结果**：三款模型（235B, 32B, 14B）均能**成功**将混合格式信息转换为正确的**JSON格式**。
*   **作者观点**: 在这个混合格式转换任务上，三款模型表现都非常不错。

(09:35-10:18) ***2.4: 代码理解与SVG格式生成测试***
*   **测试类型**：根据Python冒泡排序代码生成SVG格式的流程图。
*   **输入指令**：为下面的代码用SVG画出完整的流程图：[Python冒泡排序代码]...
*   **结果**：
    *   三款模型（235B, 32B, 14B）均生成了**SVG代码**。
    *   但是，所有模型生成的SVG代码在浏览器中打开时均**出现报错**，无法正确渲染成流程图。
*   **作者观点**: 三款模型在生成可用的SVG流程图方面都失败了。

(10:18-12:57) ***2.5: 农夫过河问题（复杂逻辑推理）***
*   **测试类型**：解决经典的农夫过河逻辑谜题。
*   **输入指令**：农夫带着一只老虎、一只羊、一条蛇、一只鸡和一筐苹果要过河...[详细规则]...请问农夫如何才能将老虎、羊、蛇、鸡和苹果安全送到对岸？
*   **结果**：
    *   **Qwen3-235B-A22B**：**失败**。在第五步“农夫带鸡过河”后，分析安全性时**产生幻觉**，错误地认为“老虎会阻止蛇吃羊”，而规则中蛇不吃羊，导致后续步骤错误。
    *   **Qwen3-32B**：**失败**。在第一步就**出错**，选择了带鸡过河，违反了鸡会阻止老虎吃羊的规则（虽然原题规则是鸡阻止蛇吃鸡，但此处模型理解或应用规则错误）。
    *   **Qwen3-14B**（开启思考模式）：**失败**。步骤给出的看似合理，但在第七步“带羊过河”后，对岸状态分析错误，认为有老虎、羊、蛇，此时老虎会吃羊，违反安全规则。
*   **作者观点**: 这个经典的农夫过河问题**难倒了所有三款Qwen3模型**，它们在多步复杂逻辑推理和状态跟踪方面存在明显不足，容易产生幻觉或违反规则。

(12:58-13:36) ***2.6: 文档分析能力测试***
*   **测试类型**：基于上传的PDF文档（Phi-4-Mini技术报告）回答问题。
*   **输入指令**：[上传PDF后提问] Phi-4-Mini具有多少个Transformer层？隐藏状态大小是多少？它使用的GQA配置具体包含多少个查询头和键/值头？...
*   **结果**：
    *   **Qwen3-235B-A22B**：**正确**回答了所有问题。
    *   **Qwen3-32B**：**部分正确**，前两个问题回答正确，第三个问题（得分提高百分点）回答错误。
    *   **Qwen3-14B**（通过Open WebUI测试）：**失败**，未能从文档中找到答案。
*   **作者观点**: **235B**表现最好。**14B**的失败可能是由于**Open WebUI**文档解析功能的问题，不完全代表模型本身的能力。

(13:36-14:17) ***2.7: 算法与编程能力测试***
*   **测试类型**：用Python编程实现计算第N个质数，要求不引入外部库。
    *   算法题：计算438990637是第多少个质数。
    *   编程题：设计一个2D物理模拟系统（涉及碰撞、旋转等）。
*   **结果**（算法题）：
    *   **Qwen3-235B-A22B**：给出的**Python代码**只做了**基本的优化**，整体效率较低。
    *   **Qwen3-32B**：给出的代码采用了**更高效**的方法，通过存储已找到的质数来加速判断。
    *   **Qwen3-14B**（开启思考模式）：给出的代码**优化程度最高**，比32B的还要好一些，例如在找到目标后能退出循环。
*   **结果**（编程题 - 2D物理模拟）：
    *   **Qwen3-235B-A22B**：生成的**Pygame代码**无法一次性运行，运行时**闪退**且没有内容，代码存在**错误**（如 'BLACK' is not defined）。
    *   **Qwen3-32B**：生成的代码同样无法一次性运行，运行时**闪退**。
    *   **Qwen3-14B**（开启思考模式）：生成的代码**能够运行**，并展示了两个六边形和一个移动的小球，但**未完全实现**题目要求的所有物理特性（如交叉区域弹跳）。
*   **作者观点**: 在算法题上，**14B**和**32B**的代码优化能力优于**235B**。在编程题上，只有**14B**生成的代码能基本运行，但功能不完善，而**235B**和**32B**生成的代码都无法直接运行。

(10:18-10:56) ***2.8: 提示词遵循能力与负责问题分析能力测试***
*   **测试类型**：模型是否能严格按照一个复杂的、包含多步骤和格式要求的提示词（Prompt）来分析和回答问题。
*   **输入指令**：你现在是一名超级思维解析师...[详细的多步骤分析要求，包括解析流程规范、使用特定符号、探索多种答案、明确能力边界、审视推理过程、应用最佳实践、JSON格式输出等]...下面是你要解决的问题：[抛硬币概率问题]。
*   **结果**：
    *   三款模型（235B, 32B, 14B）均**未能遵循**复杂的提示词指令。它们都**只给出了第一步**（输出包含“步骤”、“标题”、“内容”、“下一步行动”的JSON），而没有继续执行提示词中要求的后续分析步骤。
*   **作者观点**: 这个测试表明，Qwen3系列模型在**严格遵循复杂指令（Prompt Following）**方面存在**显著的短板**，这是一个较大的弱点。

(10:57-11:48) ***2.9: SQL能力测试***
*   **测试类型**：根据给定的数据库表结构（产品表、供应商表、客户表、采购订单表、销售订单表、库存交易表等）和5个具体问题，生成相应的SQL查询语句。
*   **结果**：
    *   **Qwen3-235B-A22B**：生成的5个SQL查询语句**全部正确**。
    *   **Qwen3-32B**：第3个问题（供应商绩效）使用的**`DATEDIFF`函数语法是SQL Server特有的**，而非通用的或MySQL的语法，其他SQL语句正确。
    *   **Qwen3-14B**（开启思考模式）：生成的5个SQL查询语句**全部正确**。
*   **作者观点**: **235B**和**14B**的SQL能力非常强，**32B**稍有不足（使用了特定数据库方言）。

# Part 5: 总体评价

(15:19-15:38) ***5.1: 作者总结***
*   **作者观点**: 通过多方面的测试，可以发现**Qwen3系列模型**在多方面的能力都**有了很大的提升**。但是，在**复杂逻辑推理**（如农夫过河）、**严格遵循提示词指令**以及**部分代码生成**（尤其是SVG）方面仍有不足。**14B参数的模型**在开启**思考模式**后，其效果常常能**媲美甚至超过**不开启思考模式的**32B模型**，有时甚至比**235B模型**效果还好一些（例如在JSON准确性、算法优化方面）。用户可以根据自己的项目需求和对模型能力侧重的不同，来选择不同参数的版本。